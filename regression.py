# -*- coding: utf-8 -*-
"""regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pBlrIkGlURycd4iWypwmKTGjLSkYJX7p
"""

import pandas as pd
import numpy as np
import math

!pip install sklearn-ts==0.0.5

"""# Load data"""

covid = pd.read_csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv")
#covid.head(2)

target = 'new_cases'
h = 14

dataset = covid[(covid['location']=='World')].copy()[[target, 'date']]
dataset[[target]].plot()

# prepare features
features = ['year', 'month', f'{h}_lag', f'{h}_lag_rolling', 'dayofweek', 'intercept', 'trend', 'log']
categorical_features = ['year', 'month', 'dayofweek']
numerical_features = [f'{h}_lag', f'{h}_lag_rolling', 'intercept', 'trend', 'log']

dataset['date'] = pd.to_datetime(dataset['date'])
dataset.index = dataset['date']
dataset['month'] = dataset['date'].dt.month
dataset['year'] = dataset['date'].dt.year
dataset['dayofweek'] = dataset['date'].dt.dayofweek
dataset[f'{h}_lag'] = dataset[target].shift(h)
dataset[f'rolling_{target}'] = dataset[target].rolling(window=h).mean()
dataset[f'{h}_lag_rolling'] = dataset[f'rolling_{target}'].shift(h)
dataset['intercept'] = 1
dataset['trend'] = range(dataset.shape[0])
dataset['log'] = dataset['trend'].apply(lambda x: math.log(x+1))
dataset = dataset[['date', target] + numerical_features +categorical_features]
dataset = dataset.dropna()

dataset[features + [target]].tail()

ax = dataset[[f'{h}_lag_rolling', 'new_cases']].plot.scatter(x=f'{h}_lag_rolling', y='new_cases')
fig = ax.get_figure()
fig.savefig('scatter.png')

ax = dataset[f'{h}_lag_rolling'].hist(bins=20)
fig = ax.get_figure()
fig.savefig('hist.png')

"""# Splitting data"""

#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html?highlight=timeseriessplit#sklearn.model_selection.TimeSeriesSplit
from sklearn.model_selection import TimeSeriesSplit

tss = TimeSeriesSplit(n_splits=2)
for train_index, test_index in tss.split(dataset):
  print(dataset.iloc[train_index].index, dataset.iloc[test_index].index)

from sklearn_ts.splitter import custom_split
from sklearn_ts.validator import check_model

custom_split(dataset, h=h, n_splits=2, gap=h)[1]

"""#Linear Regression"""

#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
from sklearn.linear_model import LinearRegression

lr_params = {'fit_intercept': [False]}
lr = LinearRegression()

results = check_model(lr, lr_params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""# Support Vector Regression"""

from sklearn.svm import SVR

svr_params = {'C': [50000, 100000], 'kernel': ['rbf']}
svr = SVR()

results = check_model(svr, svr_params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""# Trees

## Regression Trees
"""

#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html
from sklearn.tree import DecisionTreeRegressor

params = {'max_depth': [3, 5, 8, 10, 12, 15, 20], 'criterion': ['mae'], 
          'min_samples_split': [2, 4, 8, 10, 12, 15], 'min_samples_leaf': [1, 2, 3, 4, 5]}
regressor = DecisionTreeRegressor()

results = check_model(regressor, params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""# Visualization"""

rt = DecisionTreeRegressor(
    criterion='mse', 
    max_depth=3, 
    min_samples_split=4, 
    min_samples_leaf=2, 
    random_state=42, 
)

rt.fit(dataset[features], dataset[target])

dataset['pred'] = rt.predict(dataset[features])
dataset[['date', target, 'pred']].plot(x='date', y=[target, 'pred'])

#https://github.com/parrt/dtreeviz
!pip install dtreeviz
from dtreeviz.trees import dtreeviz

viz = dtreeviz(rt, dataset[features], dataset[target],
                target_name=target,
                feature_names=features)

viz

"""## RandomForest"""

from sklearn.ensemble import RandomForestRegressor

params = {'n_estimators': [100], 'criterion': ['mae'], 
          'max_depth': [8, 15], 'min_samples_split': [2, 3, 4], 
          'random_state': [42], 'min_samples_leaf': [1, 2, 3]}
regressor = RandomForestRegressor()

results = check_model(regressor, params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""## XGBoost"""

#https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn
from xgboost import XGBRegressor

params = {'n_estimators': [100, 300], 'max_depth': [8, 15, 20],'objective': ['reg:squarederror'], 'subsample': [1.0, 0.8, 0.7], 
          'learning_rate': [0.01, 0.05, 0.1, 0.5, 1]}
regressor = XGBRegressor()

results = check_model(regressor, params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""## Light GBM"""

#https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html#lightgbm.LGBMRegressor
from lightgbm import LGBMRegressor

params = {'n_estimators': [300, 400], 
          'max_depth': [8, 9, 11, 13, 15],'objective': ['regression'], 
          'learning_rate': [0.05, 0.1, 0.2], 'num_leaves': [20, 31, 40],
          'random_state': [42]}
regressor = LGBMRegressor()

results = check_model(regressor, params, dataset, features=features, categorical_features=categorical_features)
results['best_params']

"""# Summary"""

models = {
    LinearRegression(fit_intercept=False): {'fit_intercept': [False]},

    SVR(): {'C': [50000, 100000], 'kernel': ['rbf']},

    DecisionTreeRegressor(): {'max_depth': [8, 10, 12], 'criterion': ['mae'], 
          'min_samples_split': [4, 8, 10], 'min_samples_leaf': [1, 2]},

    RandomForestRegressor(): {'n_estimators': [100], 'criterion': ['mae'], 
          'max_depth': [8, 15], 'min_samples_split': [2, 3, 4], 
          'random_state': [42], 'min_samples_leaf': [1, 2, 3]},

    XGBRegressor(): {'n_estimators': [100], 'max_depth': [8, 15, 20],'objective': ['reg:squarederror'], 'subsample': [1.0]},

    LGBMRegressor(): {'n_estimators': [300], 
          'max_depth': [13, 15],'objective': ['regression'], 
          'learning_rate': [0.05, 0.1, 0.2], 'num_leaves': [20, 31],
          'random_state': [42]},
}

results_array = []
for regressor, params in models.items():
  results_array.append(check_model(regressor, params, dataset, plotting=False, features=features, categorical_features=categorical_features))

pd.DataFrame({'Model': [res['model_name'] for res in  results_array], 'MAPE': [res['performance_test']['MAPE'] for res in  results_array]}).sort_values('MAPE')

